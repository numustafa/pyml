{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start working on the exercise\n",
    "\n",
    "- Use Python version 3.7 up to 3.9. Make sure not to use Python 3.10\n",
    "- It is highly recommended to create a virtual environment for this course. You can find resources on how to create a virtual environment on the ISIS page of the course.\n",
    "- Make sure that no assertions fail or exceptions occur, otherwise points will be subtracted.\n",
    "- Use all the variables given to a function unless explicitly stated otherwise. If you are not using a variable you are doing something wrong.\n",
    "- Read the **whole** task description before starting with your solution.\n",
    "- After you submit the notebook more tests will be run on your code. The fact that no assertions fail on your computer locally does not guarantee that you completed the exercise correctly.\n",
    "- Please submit only the notebook file with its original name. If you do not submit an `ipynb` file you will fail the exercise.\n",
    "- Edit only between YOUR CODE HERE and END YOUR CODE.\n",
    "- Verify that no syntax errors are present in the file.\n",
    "- Before uploading your submission, make sure everything runs as expected. First, restart the kernel (in the menubar, select Kernel\\Restart) and then run all cells (in the menubar, select Cell\\Run All)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Python version\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "if (3,7) <= sys.version_info[:2] <= (3, 9):\n",
    "    print(\"Correct Python version\")\n",
    "else:\n",
    "    print(f\"You are using a wrong version of Python: {'.'.join(map(str,sys.version_info[:3]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c9cfdd6af660771e508cc053ad9a861e",
     "grade": false,
     "grade_id": "cell-0d8754466aa84a8c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "$$\\Large\\textbf{Python Programming for Machine Learning}$$\n",
    "\n",
    "\n",
    "\n",
    "$$\\Large\\textbf{Exam}$$\n",
    "<hr>\n",
    "\n",
    "<img src='images/TU.png' width='200'>\n",
    "<br>\n",
    "\n",
    "$$\\text{Department of Intelligent Data Analysis and Machine Learning}$$\n",
    "\n",
    "<br>\n",
    "$${29\\text{th of November}\\> 2021}$$\n",
    "\n",
    "<hr>\n",
    "\n",
    "### Read before starting with the exam!\n",
    "\n",
    "The exam has a similar format to the exercise sheets you completed throught the course.\n",
    "\n",
    "Each exercise consists of: \n",
    "- Explanation \n",
    "- Implementation\n",
    "- Overwrite\n",
    "\n",
    "The overwrite part means that after your function has been tested the expected value will be placed in the corresponding variables, so that **if you get stuck you can continue with the next exercise**. If you get stuck in a task, it highly recommended to continue to another task. Even if your solution is not correct and does not pass all the tests it will receive partial credit for the correct parts.\n",
    "\n",
    "#### If a solution cell does not compile (results in a `SystaxError`) it will receive **ZERO (0)** credits, even if the implementation is principally correct.\n",
    "\n",
    "For each exercise there will be a maximum number of loops allowed. If your function contains more loops than allowed, you will be notified during the function definition, and the function will automatically fail in the tests. Note that \"unrolling a loop\" (repeating a line many times) is also considered a loop.\n",
    "\n",
    "For technical reasons the following functions are **banned** throughout the notebook.\n",
    "\n",
    "- map\n",
    "- sum (but np.sum is allowed)\n",
    "- filter\n",
    "- np.vectorize\n",
    "- np.fromiter\n",
    "- np.fromfunction\n",
    "- np.apply_along_axis\n",
    "\n",
    "**If you use any of these functions in your solution will receive 0 points**.\n",
    "\n",
    "**Important:** \n",
    "   \n",
    "- Execute every cell in the notebook. You may also try to restart your kernel and execute all cells, in case something went wrong.\n",
    "\n",
    "- If you were not able to implement one function you may proceed with a next exercise by using data generated from the _expected_ output functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4aea5fdf4b0ff4ee40671705dc322b9d",
     "grade": false,
     "grade_id": "cell-4b8fd64ba7195577",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Personal student information\n",
    "\n",
    "In the following cell fill in your **real** personal information. Make sure that the code compiles. This information may be used later for you class certificates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Mika\"  # your first name\n",
    "MID_NAME = \"Till\"  # your middle or empty string ''\n",
    "SURNAME = \"Delor\"  # your last name\n",
    "\n",
    "MATRICULATION_NUMBER = 349949  # e.g. 412342 as integer\n",
    "\n",
    "HOME_UNIVERSITY = \"TU Berlin\"  # e.g. TU Berlin, HU Berlin, Uni Potsdam, etc...\n",
    "MODULE_NAME = \"\"  # e.g CA, ML-1, ML-2, Standalone\n",
    "COURSE_OF_STUDY = \"Computer Science\"  # e.g. Mathematics, Computer Science, Physics, etc...\n",
    "DEGREE = \"Master\"  # e.g. Erasmus, Bachelor, Diplom, Master, PhD or Guest (all others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dce405aed36ae83acad6cb6000c2d1a7",
     "grade": false,
     "grade_id": "cell-8733415e82df4138",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Hello Mika Till Delor \n",
       "### Your matriculation number is 349949 \n",
       "### You study at TU Berlin Computer Science Master \n",
       "### Module name: \n",
       "## [zoom exam room](https://tu-berlin.zoom.us/j/68316661651?pwd=Yng4TmJDcW1sU3dpMTZwWlAzQktMUT09)\n",
       "## password: 997046"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown as md\n",
    "\n",
    "md(\n",
    "    f\"## Hello {NAME} {MID_NAME} {SURNAME} \\n\"\n",
    "    f\"### Your matriculation number is {MATRICULATION_NUMBER} \\n\"\n",
    "    f\"### You study at {HOME_UNIVERSITY} {COURSE_OF_STUDY} {DEGREE} \\n\"\n",
    "    f\"### Module name: {MODULE_NAME}\\n\"\n",
    "    \"## [zoom exam room](https://tu-berlin.zoom.us/j/68316661651?pwd=Yng4TmJDcW1sU3dpMTZwWlAzQktMUT09)\\n\"\n",
    "    \"## password: 997046\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d60974856b70f539d3d26fae26af0940",
     "grade": false,
     "grade_id": "cell-2ebb1788575230f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if external packages are installed correctly.\n",
      "NumPy version ok!\n",
      "SciPy version ok!\n",
      "scikit-learn version ok!\n",
      "pandas version ok!\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking if external packages are installed correctly.\")\n",
    "try:\n",
    "    import numpy\n",
    "    import scipy\n",
    "    import sklearn\n",
    "    import pandas\n",
    "except ImportError:\n",
    "    print(\"Please install the needed packages using \\\"pip install -U numpy scipy pandas scikit-learn\\\"\")\n",
    "else:\n",
    "    numpy_version = tuple(map(int, numpy.__version__.split(\".\")))\n",
    "    scipy_version = tuple(map(int, scipy.__version__.split(\".\")))\n",
    "    sklearn_version = tuple(map(int, sklearn.__version__.split(\".\")))\n",
    "    pandas_version = tuple(map(int, pandas.__version__.split(\".\")))\n",
    "    if numpy_version >= (1, 18, 0):\n",
    "        print(\"NumPy version ok!\")\n",
    "    else:\n",
    "        print(\"Your NumPy version is too old!!!\")\n",
    "\n",
    "    if scipy_version >= (1, 6, 0):\n",
    "        print(\"SciPy version ok!\")\n",
    "    else:\n",
    "        print(\"Your SciPy version is too old!!!\")\n",
    "\n",
    "    if sklearn_version >= (1, 0):\n",
    "        print(\"scikit-learn version ok!\")\n",
    "    else:\n",
    "        print(\"Your scikit-learn version is too old!!!\")\n",
    "\n",
    "    if pandas_version >= (1, 3, 0):\n",
    "        print(\"pandas version ok!\")\n",
    "    else:\n",
    "        print(\"Your pandas version is too old!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e181f4a67b0f63ffd52324dd3e105e88",
     "grade": false,
     "grade_id": "cell-b5e24291f0afd451",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> .output_png {display: table-cell;text-align: center;vertical-align: middle;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML as Center\n",
    "\n",
    "Center(\n",
    "    \"<style> .output_png {display: table-cell;text-align: center;vertical-align: middle;}</style>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6a059f696fc825b8c7f08516526af09c",
     "grade": false,
     "grade_id": "cell-f065747eed678c1a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# The Task\n",
    "<style>\n",
    "img {\n",
    "    background-color: white;\n",
    "}\n",
    "</style>\n",
    "In this notebook we will explore a semi supervised learning task. The task is to cluster a set of datapoints given the labels of a small subset of the dataset. The original dataset looks like this: \n",
    "\n",
    "<img src=\"images/original_clusters.png\" width=\"500\" />\n",
    "\n",
    "Most of the labels have however been removed from the data that we will use in this notebook. The goal is to cluster the data back into 3 clusters.\n",
    "\n",
    "The original noisy data consists of more than 2 dimensions. We will use Principal Component Analysis (PCA) to remove the extra dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c45a2ffc8d00c27fbdb126172017d09f",
     "grade": true,
     "grade_id": "import-setup",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from minified import max_allowed_loops, no_imports\n",
    "from unittest import TestCase\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "t = TestCase()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff8073792c6a7cddf9799e467f2ece72",
     "grade": false,
     "grade_id": "cell-5a9ed50a7dc71388",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise 1: Data loading, initial data exploration and visualization\n",
    "\n",
    "In this exercise we will load the data from the file. Then we will apply Principal Component Analysis (PCA) to determine how many components of the dataset are actually useful for our purposes. Then we will create two plots. The first one will regard the explained variance of each component after PCA has been applied. After that we will remove the components which we deem superfluous and will plot the transformed data as a scatter plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "78c06c6af128b9126bdc8fa9d0d469c2",
     "grade": false,
     "grade_id": "cell-e1b01f636f4b84c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1.1: Read from CSV using Pandas (5 points).\n",
    "\n",
    "Implement a function that loads a CSV file as a Pandas DataFrame. You can use any Pandas\n",
    "functions you want. However you cannot use any loops in the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e7a32206d2c960c6b21360466b4e437",
     "grade": false,
     "grade_id": "ex1-1-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "@no_imports\n",
    "@max_allowed_loops(0)\n",
    "def read_data(filename: str) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Read data from a CSV file and return a pandas DataFrame. If the file does not\n",
    "    exists, the function returns `None`.\n",
    "\n",
    "    Args:\n",
    "        filename: The name of the CSV file to read\n",
    "\n",
    "    Returns:\n",
    "        A Pandas DataFrame containing the data\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    try:\n",
    "        return pd.read_csv(filename)\n",
    "    except:\n",
    "        return None\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b79d511105eaac1c40354fd58b44cf7",
     "grade": true,
     "grade_id": "ex1-1-test",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    varA   varB   varC   varD   varE   varF  label\n",
      "0 -0.070 -0.547 -0.028  0.791  0.119  0.004     -1\n",
      "1  0.073  3.632 -0.019  4.516 -0.071  0.135     -1\n",
      "2 -0.410  0.608 -0.125 -0.182 -0.045 -0.062     -1\n",
      "3  0.669  0.490  0.129  0.665 -0.050  0.211     -1\n",
      "4  0.102  1.627  0.140  0.371  0.180  0.062     -1\n"
     ]
    }
   ],
   "source": [
    "tiny_df = read_data(\"tiny.csv\")\n",
    "expected_tiny_df = pd.DataFrame(\n",
    "    {\n",
    "        \"varA\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6],\n",
    "        \"varB\": [0.2, 0.3, 0.4, 0.5, 0.6, 0.7],\n",
    "        \"varC\": [0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
    "        \"label\": [1, 2, 0, -1, -1, -1],\n",
    "    }\n",
    ")\n",
    "\n",
    "pd.testing.assert_frame_equal(expected_tiny_df, tiny_df)\n",
    "\n",
    "data_df = read_data(\"data.csv\")\n",
    "\n",
    "# check column names\n",
    "np.testing.assert_array_equal(\n",
    "    data_df.columns, [\"varA\", \"varB\", \"varC\", \"varD\", \"varE\", \"varF\", \"label\"]\n",
    ")\n",
    "\n",
    "# check data types of columns\n",
    "np.testing.assert_array_equal(data_df.dtypes, [np.float64] * 6 + [np.int64])\n",
    "\n",
    "# check first row\n",
    "np.testing.assert_array_almost_equal(\n",
    "    data_df.head(1).values[0], [-0.07, -0.547, -0.028, 0.791, 0.119, 0.004, -1.0],\n",
    ")\n",
    "\n",
    "print(data_df.head(5))\n",
    "\n",
    "should_be_none = read_data(\"not_a_file.csv\")\n",
    "t.assertIsNone(should_be_none)\n",
    "\n",
    "read_data.assert_no_imports()\n",
    "read_data.assert_not_too_many_loops()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c546fb5b291a1ef5f4c74fd620ae3400",
     "grade": true,
     "grade_id": "ex1-1-overwrite",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from expected import get_exercise_1_1\n",
    "\n",
    "data_df = get_exercise_1_1()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "44c972e1044f34cc41255d85267e0b49",
     "grade": false,
     "grade_id": "cell-21b62fbabc4837f0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1.2: Perform PCA using scikit-learn (5 points).\n",
    "\n",
    "The data that we just loaded consists of 6 dimensions and a label. However, only two of the dimensions contain data relevant for the task. The other dimensions contain gaussian noise. In this task we want to extract the useful information from the dataset using [Principal Component Analysis](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) (PCA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f41fe5f18b16e18300c091c6519bdbd7",
     "grade": false,
     "grade_id": "cell-8bcefec3b20ce91d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "@no_imports\n",
    "@max_allowed_loops(0)\n",
    "def transform_data_pca(\n",
    "    data: np.ndarray, n_components: Optional[int] = None\n",
    ") -> Tuple[np.ndarray, PCA]:\n",
    "    \"\"\"\n",
    "    Perform PCA on the data and return the transformed data.\n",
    "\n",
    "    Args:\n",
    "        data: A numpy array containing the data to transform\n",
    "        n_components: The number of components (dimensions) to keep (relevant argument\n",
    "        for PCA). If it is set to None, all components are kept.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the transformed data and the PCA instance\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pca = PCA(n_components=n_components)\n",
    "    transformed_data = pca.fit_transform(data)    \n",
    "    print(transformed_data)\n",
    "    return transformed_data\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "850d3bbf26a4ae71bf148117d4405e84",
     "grade": true,
     "grade_id": "cell-65dd811517292831",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.10389606 -0.01779664]\n",
      " [-0.0157286   0.02938915]\n",
      " [ 0.11962465 -0.01159251]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17776/440226741.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# apply pca for example data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mtiny_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtiny_pca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform_data_pca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtiny_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;31m# check return types\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massertIsInstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtiny_pca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "tiny_data = np.array(\n",
    "    [\n",
    "        [0.1, 0.0],\n",
    "        [0.2, 0.0],\n",
    "        [0.3, 0.1],\n",
    "    ]\n",
    ")\n",
    "\n",
    "tiny_expected = np.array(\n",
    "    [\n",
    "        [-0.10389606, -0.01779664],\n",
    "        [-0.0157286, 0.02938915],\n",
    "        [0.11962465, -0.01159251],\n",
    "    ]\n",
    ")\n",
    "# apply pca for example data\n",
    "tiny_result, tiny_pca = transform_data_pca(tiny_data)\n",
    "# check return types\n",
    "t.assertIsInstance(tiny_pca, PCA)\n",
    "t.assertIsInstance(tiny_result, np.ndarray)\n",
    "# in the tiny example, the first component is responsible for most of the variance\n",
    "# therefore, the first component's explained variance is very close to 1\n",
    "t.assertGreater(tiny_pca.explained_variance_ratio_[0], 0.95)\n",
    "t.assertLess(tiny_pca.explained_variance_ratio_[1], 0.05)\n",
    "np.testing.assert_array_almost_equal(tiny_expected, tiny_result)\n",
    "\n",
    "\n",
    "# the labels should not be used for PCA\n",
    "data_array = data_df.values[:, :-1]\n",
    "transformed_data_array, pca = transform_data_pca(data_array)\n",
    "\n",
    "# check that pca instance has been fitted\n",
    "check_is_fitted(pca)\n",
    "np.testing.assert_array_equal(data_array.shape, transformed_data_array.shape)\n",
    "\n",
    "# check that n_components is respected\n",
    "transformed_data_array_two_components, _ = transform_data_pca(\n",
    "    data_array, n_components=2\n",
    ")\n",
    "np.testing.assert_array_equal(transformed_data_array_two_components.shape, (998, 2))\n",
    "\n",
    "transform_data_pca.assert_no_imports()\n",
    "transform_data_pca.assert_not_too_many_loops()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "475c3eee9bf66b5b007eb6532db99242",
     "grade": true,
     "grade_id": "cell-f9f59547c4f629be",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from expected import get_exercise_1_2\n",
    "\n",
    "transformed_data_array = get_exercise_1_2()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "622baf89d3ac4d04a1eb603d6e775aeb",
     "grade": false,
     "grade_id": "cell-115470391c17440a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise 1.3: Plotting the explained variance for each transformed dimension (10 points).\n",
    "\n",
    "* Plot the cumulative explained variance for each component.\n",
    "* Use the `explained_variance_ratio_` member of the PCA instance.\n",
    "* Draw a line plot for the cumulative explained variance. The markers should be visible as circles.\n",
    "* Draw a red, dashed horizontal line at the threshold ratio.\n",
    "* The horizontal ticks should have a range from `1` up to the number of components.\n",
    "* The title of the x-axis should be `Number of components`.\n",
    "* The title of the y-axis should be `Cumulative explained variance`.\n",
    "* The title of the plot should be `Cumulative expalined variance against number of components kept`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc2c04d51df71c2bbf1e6f33714fb03b",
     "grade": true,
     "grade_id": "cell-8a830ddcc617eb65",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@no_imports\n",
    "@max_allowed_loops(0)\n",
    "def plot_pca_variance(pca: PCA, threshold: float = 0.95) -> None:\n",
    "    \"\"\"\n",
    "    Plot the explained variance of the PCA. A line plot is drawn for the cumulative\n",
    "    explained variance of the components. A dashed horizontal line is drawn for the\n",
    "    threshold.\n",
    "\n",
    "    Args:\n",
    "        pca: The PCA instance to use to plot the explained variance\n",
    "        threshold: The threshold for the explained variance to use for plotting\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError(\"Relplace this line with your code\")\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81fa683b8a284a4bf5d8e21847b01639",
     "grade": false,
     "grade_id": "cell-4c8aaf7845af79df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plot_pca_variance(pca)\n",
    "plot_pca_variance.assert_no_imports()\n",
    "plot_pca_variance.assert_not_too_many_loops()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4cd2003dd0cc2438efb6f145751ca8b3",
     "grade": false,
     "grade_id": "cell-3d07c6165eb89d15",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<style>\n",
    "img {\n",
    "  background-color: rgb(300, 300, 300);\n",
    "}\n",
    "</style>\n",
    "\n",
    "### This is a plot that you can use as a reference\n",
    "![Reference image for task 1.3](images/pca_variance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fc162a6233aa5d2e366c0e668373d337",
     "grade": false,
     "grade_id": "cell-b3ba6192401288e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "From the above plot we see that the first two components explain most (> 95%) of the variance therefore we can keep only the first two components after transformation.\n",
    "\n",
    "For the rest of the exercises we will use the transformed data and the labels. The following cell creates the two variables which contain the data and the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5069468ab40cd3bf7be65af8b123259",
     "grade": false,
     "grade_id": "cell-90bc58221c32672d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = transformed_data_array[:, :2]\n",
    "labels = data_df[\"label\"].values\n",
    "\n",
    "print(data.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bdcf0bd22a5563cd75c98593eccf7012",
     "grade": false,
     "grade_id": "cell-87332bba3f5be5df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise 1.4: Plotting the clusters of the transformed data (20 points).\n",
    "\n",
    "Create a scatter plot of the data, which visualizes the data with the known labels\n",
    "the means of each cluster and the unlabeled data. Below you can find a scatter plot that you can use as a reference. Use the `plt.plot` function to create the plots not `plt.scatter`.\n",
    "\n",
    "Title:\n",
    "* Title should be set according to the provided argument\n",
    "* Font size: `25`.\n",
    "\n",
    "Legend:\n",
    "* Font size: `20`.\n",
    "\n",
    "Elements for which the label is not known (`label == -1`):\n",
    "* Marker shape should be a circle.\n",
    "* Marker color should be black.\n",
    "* Marker alpha should be `0.1`.\n",
    "* The label should be \"Unlabeled\".\n",
    "\n",
    "Elements for which the label is known:\n",
    "* Marker shape should be a square.\n",
    "* Marker color should be unique for each cluster.\n",
    "* Marker alpha should be `0.75`.\n",
    "* Marker size should be 50 (use `s` argument).\n",
    "* Markers should be drawn above all unlabeled points (use `zorder`).\n",
    "* The label of each cluster should be \"Cluster {label}: {number_of_elements_in_cluster}\". For example: \"Cluster 0: 10\".\n",
    "\n",
    "The means of each cluster:\n",
    "* Marker shape should be a cross.\n",
    "* Marker color should be red.\n",
    "* Marker size should be 100 (use `s` argument).\n",
    "* Markes should be drawn above all other markers (use `zorder`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "177b6a0de714de4eace13aea5847b360",
     "grade": true,
     "grade_id": "cell-e3ecc42a07f53391",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@no_imports\n",
    "@max_allowed_loops(1)\n",
    "def plot_clusters(X: np.ndarray, y: np.ndarray, title: str = \"\") -> None:\n",
    "    \"\"\"\n",
    "    Plot the data. Datapoints for which the cluster label is known are plotted\n",
    "    differently compared to datapoints for which the label is unknown.\n",
    "\n",
    "    The empirical mean of each cluster is also plotted.\n",
    "\n",
    "    Args:\n",
    "        X: The data to plot\n",
    "        y: The cluster labels (if the cluster is not known the label is `-1`)\n",
    "        title: The title of the plot\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb15824e421449846a11d82c5e03ad0c",
     "grade": false,
     "grade_id": "cell-c6b2a9847fb583ab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plot_clusters(data, labels, \"Data distribution\")\n",
    "plot_clusters.assert_no_imports()\n",
    "plot_clusters.assert_not_too_many_loops()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "db388e755eab7587849ff2ddbc1a6bb8",
     "grade": false,
     "grade_id": "cell-5b22e31e0d195612",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<style>\n",
    "img {\n",
    "  background-color: rgb(300, 300, 300);\n",
    "}\n",
    "</style>\n",
    "\n",
    "### This is a plot that you can use as a reference\n",
    "<!-- ![Reference image for task 2.1](images/clusters.png) -->\n",
    "<img src=\"images/clusters.png\" alt=\"A reference scatter plot for exercise 1.4\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "75db40a260ca6db6fdf40da70194d9c6",
     "grade": false,
     "grade_id": "cell-aea3f8070005f8ac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise 2: Initialization steps\n",
    "\n",
    "Our goal is to assign a cluster for each data-point. We will model the three clusters as three multivariate normal distributions. Therefore we need to estimate the parameters of each distribution. The algorithm that we use is iterative and requires an initialization for the parameters. Since we model the distributions using multivariate normal distributions we need to specify three parameters, the mean of each cluster ($\\Large{\\mu}$), the covariance matrix of each gaussian ($\\Large{\\Sigma}$) and the proportion of elements in each cluster ($\\Large{\\pi}$). In Exercise 3 we will implement the algorithm that estimates the correct parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0108da73080d0b68f21077eff2ccc578",
     "grade": false,
     "grade_id": "cell-e0e552bd65d992b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise 2.1: Initial estimation of cluster means (7 points).\n",
    "\n",
    "Calculate the empirical cluster mean for each cluster based on labeled data-points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed0558464577d9a63e33046cb28a3b0f",
     "grade": false,
     "grade_id": "cell-c48de01d095fd27c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@no_imports\n",
    "@max_allowed_loops(1)\n",
    "def initialize_mus(X: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Initialize the means of the clusters. The empirical mean of each cluster\n",
    "    is calculated and used as the initial mean. If a datapoint does not have a label\n",
    "    assigned to it (`label == -1`) then it is not considered for the mean calculation.\n",
    "\n",
    "    Args:\n",
    "        X: The datapoints\n",
    "        y: The cluster labels (if the cluster is not known the label is `-1`)\n",
    "\n",
    "    Returns:\n",
    "        The initial, empirical means\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return mus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9632cfdb95c4c144d3ba2ab08d3ddcae",
     "grade": true,
     "grade_id": "cell-3751f8afe758dd21",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_data = np.random.randn(100, 2)\n",
    "\n",
    "# test case with the same label everywhere\n",
    "test_labels = np.zeros(len(test_data), dtype=np.int64)\n",
    "test_result = initialize_mus(test_data, test_labels)\n",
    "np.testing.assert_array_equal(test_result.shape, (1, 2))\n",
    "expected_result = np.mean(test_data, axis=0, keepdims=True)\n",
    "np.testing.assert_array_equal(test_result, expected_result)\n",
    "\n",
    "# test that values with no label are not used for the mean calculation\n",
    "# create random data with non-label\n",
    "random_data_to_add = np.random.rand(100, 2)\n",
    "non_labels = np.full(len(random_data_to_add), -1)\n",
    "test_data = np.concatenate((test_data, random_data_to_add))\n",
    "test_labels = np.concatenate((test_labels, non_labels))\n",
    "\n",
    "# calculate again (result should be the same)\n",
    "new_result = initialize_mus(test_data, test_labels)\n",
    "np.testing.assert_array_equal(new_result.shape, (1, 2))\n",
    "np.testing.assert_array_almost_equal(new_result, test_result)\n",
    "\n",
    "# add second cluster\n",
    "new_cluster_data = np.random.rand(20, 2) + [2, 2]\n",
    "new_cluster_labels = np.full(len(new_cluster_data), 1)\n",
    "test_data = np.concatenate((test_data, new_cluster_data))\n",
    "test_labels = np.concatenate((test_labels, new_cluster_labels))\n",
    "\n",
    "two_clusters_result = initialize_mus(test_data, test_labels)\n",
    "np.testing.assert_array_equal(two_clusters_result.shape, (2, 2))\n",
    "# first cluster mean should stay the same\n",
    "np.testing.assert_array_almost_equal(two_clusters_result[0], expected_result[0])\n",
    "# second cluster mean should be the mean of the new cluster\n",
    "np.testing.assert_array_almost_equal(\n",
    "    two_clusters_result[1], np.mean(new_cluster_data, axis=0)\n",
    ")\n",
    "\n",
    "# test with shuffled data (results should stay the same)\n",
    "shuffle_idx = np.random.rand(len(test_data)).argsort()\n",
    "test_data = test_data[shuffle_idx]\n",
    "test_labels = test_labels[shuffle_idx]\n",
    "shuffle_result = initialize_mus(test_data, test_labels)\n",
    "np.testing.assert_array_almost_equal(shuffle_result, two_clusters_result)\n",
    "\n",
    "\n",
    "mus = initialize_mus(data, labels)\n",
    "print(mus)\n",
    "np.testing.assert_array_equal(mus.shape, (3, 2))\n",
    "\n",
    "initialize_mus.assert_no_imports()\n",
    "initialize_mus.assert_not_too_many_loops()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e7d13465ac3f04c027ec9f7297d69bf",
     "grade": true,
     "grade_id": "cell-cffbc9a67b18ea0a",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from expected import get_exercise_2_1\n",
    "\n",
    "mus = get_exercise_2_1()\n",
    "number_of_clusters = len(mus)\n",
    "print(f\"Number of clusters: {number_of_clusters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8fffe9f187133d5cf77ff16782161a91",
     "grade": false,
     "grade_id": "cell-5a26fcab7305257e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise 2.2: Initialization of covariance matrices (5 points).\n",
    "\n",
    "Implement a function that initializes the covariance matrix for each cluster. All clusters are initialized with the same covariance matrix which contains the \n",
    "\n",
    "* Initialize diagonal covariance matrices for each cluster.\n",
    "* The shape of the output should be (K, d, d) where $K$ is the number of clusters and $d$ is the dimensionality of the data.\n",
    "* **Broadcasting hint**: $(K, d, 1) \\times (1, d, d) = (K, d, d)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "111bdf28ec11512d87eb33df96626ba4",
     "grade": false,
     "grade_id": "cell-fb71e773aad06bb7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@max_allowed_loops(0)\n",
    "@no_imports\n",
    "def initialize_sigmas(K: int, d: int, initial_value: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Initialize the covariance matrix for each cluster. The initial covariance matrix for\n",
    "    each cluster is a diagonal matrix with the diagonal elements equal to\n",
    "    `initial_value`.\n",
    "\n",
    "    Args:\n",
    "        K: The number of clusters\n",
    "        d: The dimension of the data\n",
    "        initial_value: The initial value for the diagonal elements of the covariance\n",
    "        matrix\n",
    "\n",
    "    Returns:\n",
    "        The initial covariance matrices (shape = (K,d,d))\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError(\"Relplace this line with your code\")\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d3b8c384dbdefb7e1493fb8f55e05d58",
     "grade": true,
     "grade_id": "cell-ab067d52481ad7eb",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_sigmas = initialize_sigmas(5, 3, 1)\n",
    "t.assertEqual(test_sigmas.dtype, np.float64)\n",
    "np.testing.assert_array_equal(test_sigmas.shape, (5, 3, 3))\n",
    "for covariance_matrix in test_sigmas:\n",
    "    np.testing.assert_array_equal(covariance_matrix, np.eye(3))\n",
    "\n",
    "d = data.shape[1]\n",
    "\n",
    "sigmas = initialize_sigmas(number_of_clusters, d, 0.1)\n",
    "print(f\"Shape of sigmas: {sigmas.shape}\")\n",
    "print(sigmas)\n",
    "t.assertEqual(sigmas.shape, (number_of_clusters, d, d))\n",
    "\n",
    "initialize_sigmas.assert_no_imports()\n",
    "initialize_sigmas.assert_not_too_many_loops()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec974144798648622c707cf4dca05cb3",
     "grade": true,
     "grade_id": "cell-ca4d598ab8efb5ad",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from expected import get_exercise_2_2\n",
    "\n",
    "sigmas = get_exercise_2_2()\n",
    "print(sigmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9838ca236e3950662f4f7771829a4bf7",
     "grade": false,
     "grade_id": "cell-045a334eb70261b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise 2.3: Initialize proportions $\\pi$  (3 points).\n",
    "\n",
    "Implement a function that initializes the proportions of each cluster. We initialize all clusters with the same proportions. Keep in mind that the sum of the proportions should be `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9622c673f238e52d95b62ab6b6634d0",
     "grade": false,
     "grade_id": "cell-c39dde44f46e6142",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@max_allowed_loops(0)\n",
    "@no_imports\n",
    "def initialize_pi(number_of_clusters: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Initialize the pi vector. The pi vector is a vector of length `number_of_clusters`\n",
    "    with all elements equal to `1 / number_of_clusters`.\n",
    "\n",
    "    Args:\n",
    "        number_of_clusters: The number of clusters\n",
    "\n",
    "    Returns:\n",
    "        A vector of length `number_of_clusters` with all elements equal to\n",
    "        `1 / number_of_clusters`\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc46f00c4671d63857975c9569b819bb",
     "grade": true,
     "grade_id": "cell-324b0cdc9b9b713e",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(2, 100):\n",
    "    pi = initialize_pi(i)\n",
    "    np.testing.assert_almost_equal(np.sum(pi), 1)\n",
    "    np.testing.assert_array_equal(pi.shape, (i,))\n",
    "    np.testing.assert_almost_equal(pi, 1 / i)\n",
    "\n",
    "\n",
    "pi = initialize_pi(number_of_clusters)\n",
    "print(pi)\n",
    "\n",
    "initialize_pi.assert_no_imports()\n",
    "initialize_pi.assert_not_too_many_loops()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe2f20da0010351279415e037a3dc3ea",
     "grade": true,
     "grade_id": "cell-df1eb24caf5a027a",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from expected import get_exercise_2_3\n",
    "\n",
    "pi = get_exercise_2_3()\n",
    "print(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1bba55fef45f7d40bb3363e13921ea85",
     "grade": false,
     "grade_id": "cell-3a58c9f95bc24574",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise 3: Determining distribution parameters\n",
    "\n",
    "In this exercise we will compute the distribution parameters for each cluster. The algorithm that we implement is iterative. It consists of the following steps:\n",
    "\n",
    "0. Initialize the required parameters of the cluster distributions ($\\Large{\\mu}$, $\\Large{\\Sigma}$ and $\\Large{\\pi}$) (we did this in exercise 2).\n",
    "1. Calculate the cluster assignments according to the current distribution parameters ($\\Large{\\gamma}$).\n",
    "2. Compute the proportion of points assigned to each cluster ($\\Large{\\varphi}$).\n",
    "3. Update the proportions ($\\Large{\\pi}$).\n",
    "4. Update means ($\\Large{\\mu}$).\n",
    "5. Update sigmas ($\\Large{\\Sigma}$).\n",
    "6. Repeat steps 1-5 for a number of iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fb45eea8c2490129b98f5e8582fff6e8",
     "grade": false,
     "grade_id": "cell-185d2dc5de3d42cf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise 3.1: Cluster assignments (8+7 points).\n",
    "\n",
    "* Compute the soft cluster assignments $\\Large{\\gamma}$ for each data point and each cluster $\\Large{\\gamma \\in \\mathbb{R}^{(N,K)}}$, where $N$ is the number of datapoints and $K$ is the number of clusters.\n",
    "* *Hint*: We use the term **soft** assignment because the cluster assignment is based on the probability and is not a binary assignment.\n",
    "\n",
    "We split the calculation of the gamma matrix into steps. The calculation of the intermediary (unnormalized) $\\hat \\gamma$ matrix which is then used for the calculation of the final $\\gamma$ matrix\n",
    "\n",
    "$$\\Large{\n",
    "\\hat \\gamma_{nk} = \\log \\pi_{k} + \\log \\mathcal{N}(x_n |\\mu_k, \\Sigma_k)\n",
    "},$$\n",
    "\n",
    "where $\\mathcal{N}$ is the normal distribution. In order to evaluate the probability density function (pdf) of the multivariate normal distribution we use the `scipy.stats` module. It already has a [`multivariate_normal`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.multivariate_normal.html) class implemented. This class has methods which evaluate the pdf.\n",
    "\n",
    "$$\\Large{\n",
    "\\gamma_{nk} = \\exp{\\Big(\\hat \\gamma_{nk} - \\log\\sum_{k=1}^K \\exp{\\hat \\gamma_{nk}} \\Big)}\n",
    "}$$\n",
    "\n",
    "We import a special `scipy` function `logsumexp`. This function calculates the logarithm of the sum of exponential values in a numerically stable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "04d44a130901348f70ab510d8cff06b9",
     "grade": false,
     "grade_id": "cell-4b68dcdf293b1b56",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "pi.shape, mus.shape, sigmas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c2aa8772a6792fbfdb79af4d004a7ad",
     "grade": false,
     "grade_id": "cell-05dbb602cf91268a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "from scipy.special import logsumexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "55561f635d2f89fab0772b104fed44d4",
     "grade": false,
     "grade_id": "cell-aee227880ace3231",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@no_imports\n",
    "@max_allowed_loops(1)\n",
    "def calc_gamma_hat(\n",
    "    X: np.ndarray, pi: np.ndarray, mus: np.ndarray, sigmas: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate the intermediary variable `gamma_hat`.\n",
    "\n",
    "    One loop is allowed in this function (to iterrate over the clusters).\n",
    "\n",
    "    Args:\n",
    "        X: The datapoints\n",
    "        pi: The proportionality of the clusters\n",
    "        mus: The means of the clusters\n",
    "        sigmas: The covariance matrices of the clusters\n",
    "\n",
    "    Returns:\n",
    "        The intermediary variable `gamma_hat`\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError(\"Relplace this line with your code\")\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return gamma_hat\n",
    "\n",
    "\n",
    "@no_imports\n",
    "@max_allowed_loops(0)\n",
    "def calc_gamma(X: np.ndarray, gamma_hat: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate the gamma variable (the cluster membership/assignmen).\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError(\"Relplace this line with your code\")\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd9bc24c3338d30b6448a516ed2cb442",
     "grade": true,
     "grade_id": "cell-abc029d36cae66a6",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test calc_gamma_hat\n",
    "\n",
    "test_data = np.array([[0, 0], [1, 1], [2, 2], [3, 3]])\n",
    "test_pi = np.array([0.4, 0.2, 0.4])\n",
    "test_mus = np.array([[1, 1], [2, 2], [10, 0]])\n",
    "test_sigmas = np.array([[[1, 0], [0, 1]], [[1, 0], [0, 1]], [[1, 0], [0, 1]]])\n",
    "\n",
    "test_expected = np.array(\n",
    "    [\n",
    "        [-3.7541678, -7.44731498, -52.7541678],\n",
    "        [-2.7541678, -4.44731498, -43.7541678],\n",
    "        [-3.7541678, -3.44731498, -36.7541678],\n",
    "        [-6.7541678, -4.44731498, -31.7541678],\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_gamma_hat = calc_gamma_hat(test_data, test_pi, test_mus, test_sigmas)\n",
    "np.testing.assert_array_almost_equal(test_gamma_hat, test_expected)\n",
    "\n",
    "gamma_hat = calc_gamma_hat(data, pi, mus, sigmas)\n",
    "\n",
    "np.testing.assert_array_equal(gamma_hat.shape, (len(data), number_of_clusters))\n",
    "\n",
    "calc_gamma_hat.assert_no_imports()\n",
    "calc_gamma_hat.assert_not_too_many_loops()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "245aab422a3629714ba271ddd9dfb57a",
     "grade": true,
     "grade_id": "cell-ea679f7c1d83c584",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from expected import get_exercise_3_1_1\n",
    "\n",
    "gamma_hat = get_exercise_3_1_1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e3b00054c40f7c01f9a71c7cfd61618",
     "grade": true,
     "grade_id": "cell-d2d47e8d4c1da45c",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test calc_gamma\n",
    "\n",
    "tiny_gamma_hat = np.array(\n",
    "    [\n",
    "        [-2.62691576, -2.53697252],\n",
    "        [-2.63398571, -2.56876935],\n",
    "        [-2.69676151, -2.5408029],\n",
    "        [-2.68167031, -2.53749726],\n",
    "        [-2.61754641, -2.73595763],\n",
    "        [-2.58501002, -2.61721525],\n",
    "        [-2.62330296, -2.5472246],\n",
    "        [-3.19636988, -2.84764893],\n",
    "        [-2.9908493, -2.62973659],\n",
    "        [-2.55362679, -2.58517013],\n",
    "    ]\n",
    ")\n",
    "\n",
    "tiny_gamma = calc_gamma(tiny_data, tiny_gamma_hat)\n",
    "tiny_expected = np.array(\n",
    "    [\n",
    "        [0.47752934, 0.52247066],\n",
    "        [0.48370169, 0.51629831],\n",
    "        [0.46108918, 0.53891082],\n",
    "        [0.46401904, 0.53598096],\n",
    "        [0.52956826, 0.47043174],\n",
    "        [0.50805061, 0.49194939],\n",
    "        [0.48098958, 0.51901042],\n",
    "        [0.41369262, 0.58630738],\n",
    "        [0.41069024, 0.58930976],\n",
    "        [0.50788518, 0.49211482],\n",
    "    ]\n",
    ")\n",
    "np.testing.assert_array_equal(tiny_gamma.shape, tiny_gamma_hat.shape)\n",
    "np.testing.assert_almost_equal(tiny_gamma, tiny_expected)\n",
    "\n",
    "gamma = calc_gamma(data, gamma_hat)\n",
    "print(f\"Gamma shape: {gamma.shape}\")\n",
    "print(f\"Gamma: {gamma}\")\n",
    "\n",
    "\n",
    "calc_gamma.assert_no_imports()\n",
    "calc_gamma.assert_not_too_many_loops()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e7b2a1cbd3eaa7f69b991d0a8f49461",
     "grade": true,
     "grade_id": "cell-7fc9dabcdccd81a3",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from expected import get_exercise_3_1_2\n",
    "\n",
    "gamma = get_exercise_3_1_2()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "edd209ca5c6491a07cf1768e30fefca6",
     "grade": false,
     "grade_id": "cell-16983dfdbdbdd7c6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise 3.2: Compute the cluster soft number of datapoints $\\varphi$ from soft cluster assignments $\\gamma$  (2 points).\n",
    "\n",
    "* Compute the soft (probably assigned) number of cluster points $\\Large{\\varphi} \\in \\mathbb{R}^{K}$.\n",
    "\n",
    "$$\\Large{\n",
    "\\varphi_k = \\sum_{n=1}^N \\gamma_{nk}\n",
    "}$$\n",
    "\n",
    "* Implement a function that calculates the vector $\\Large{\\varphi}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "080d6f2a3b70e302a73f0c922bb44323",
     "grade": false,
     "grade_id": "cell-f6ce21b9f461ba85",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@no_imports\n",
    "@max_allowed_loops(0)\n",
    "def update_varphi(gamma: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate the proportionality of the clusters.\n",
    "\n",
    "    Args:\n",
    "        gamma: The cluster membership/assignment\n",
    "\n",
    "    Returns:\n",
    "        The proportionality of the clusters\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError(\"Relplace this line with your code\")\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "879d64437e2434340e045ead0a20f6ac",
     "grade": true,
     "grade_id": "cell-1e5e605c5851673e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TESTS\n",
    "test_gamma = np.arange(20).reshape(4, 5)\n",
    "test_varphi = update_varphi(test_gamma)\n",
    "test_expected = [30, 34, 38, 42, 46]\n",
    "\n",
    "np.testing.assert_array_equal(test_varphi, test_expected)\n",
    "\n",
    "varphi = update_varphi(gamma)\n",
    "print(varphi)\n",
    "\n",
    "update_varphi.assert_no_imports()\n",
    "update_varphi.assert_not_too_many_loops()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9cdea3f0f1e3074e47942c5093a56b31",
     "grade": true,
     "grade_id": "cell-111a34c877756ae8",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from expected import get_exercise_3_2\n",
    "\n",
    "varphi = get_exercise_3_2()\n",
    "print(varphi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "755de8fe62fc87129c21934ff5551dfd",
     "grade": false,
     "grade_id": "cell-e239535085aa8019",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise 3.3: Compute the cluster proportions (3 points).\n",
    "\n",
    "Compute the update to vector $\\Large{\\pi} \\in \\mathbb{R}^{K}$ using the soft number of cluster points $\\Large{\\varphi}$.\n",
    "\n",
    "$$\\Large{\n",
    "\\pi_k = \\frac{\\varphi_k}{\\sum_{k'=1}^K{\\varphi_{k'}}} \n",
    "}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f55c305fc7bbd00de84eb6bdcf0a7fab",
     "grade": false,
     "grade_id": "cell-9ff9e4b49027e54e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@no_imports\n",
    "@max_allowed_loops(0)\n",
    "def update_pi(varphi: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate the cluster proportions.\n",
    "\n",
    "    Args:\n",
    "        varphi: The proportionality of the clusters\n",
    "\n",
    "    Returns:\n",
    "        The normalized cluster proporitons\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError(\"Relplace this line with your code\")\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ddd51c6ee2414d1a3b1188dfbd26fd46",
     "grade": true,
     "grade_id": "cell-97f3da518e6ca19e",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tiny_varphi = np.array([1, 2, 3, 4, 5])\n",
    "tiny_pi = update_pi(tiny_varphi)\n",
    "tiny_expected = np.array([0.06666667, 0.13333333, 0.2, 0.26666667, 0.33333333])\n",
    "\n",
    "np.testing.assert_array_almost_equal(tiny_pi, tiny_expected)\n",
    "\n",
    "new_pi = update_pi(varphi)\n",
    "\n",
    "update_pi.assert_no_imports()\n",
    "update_pi.assert_not_too_many_loops()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f2e79f5d6c81a8fb1697457df009163b",
     "grade": true,
     "grade_id": "cell-97ef43a5401c5fb0",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from expected import get_exercise_3_3\n",
    "\n",
    "new_pi = get_exercise_3_3()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "419b05e70ca703401da041a10c28ac2e",
     "grade": false,
     "grade_id": "cell-75d70c12e14f6153",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise 3.4: Compute the cluster means update (10 points).\n",
    "\n",
    "* Compute the updated cluster means $\\Large{\\mu \\in \\mathbb{R}^{(K, d)}}$.\n",
    "\n",
    "* **Broadcasting hint**: $(N, K, 1) \\times (N, 1, d) = (N, K, d)$\n",
    "\n",
    "$$\\Large{\n",
    "\\mu_k = \\frac{\\sum_{n=1}^N \\gamma_{nk} x_n}{\\varphi_k}\n",
    "}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57638d01fb0dc20181dde82776687fa3",
     "grade": false,
     "grade_id": "cell-83cdec3413660374",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@no_imports\n",
    "@max_allowed_loops(0)\n",
    "def update_mus(X: np.ndarray, gamma: np.ndarray, varphi: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate the updated cluster means.\n",
    "\n",
    "    Args:\n",
    "        X: The datapoints\n",
    "        gamma: The cluster membership/assignment\n",
    "        varphi: The proportionality of the clusters\n",
    "\n",
    "    Returns:\n",
    "        The updated cluster means\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    " \n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8bb6c7893abb0a88e9e98ffee1c28445",
     "grade": true,
     "grade_id": "cell-ca280c6d315f4ad3",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_data = np.array(\n",
    "    [\n",
    "        [0.21014903, 0.89282556],\n",
    "        [0.75536409, 0.02637648],\n",
    "        [0.66705399, 0.35824495],\n",
    "        [0.55629719, 0.82639328],\n",
    "        [0.3658324, 0.09139075],\n",
    "        [0.73604152, 0.90614361],\n",
    "        [0.8678328, 0.41940463],\n",
    "        [0.60881363, 0.20621991],\n",
    "        [0.21109166, 0.59119766],\n",
    "        [0.66903319, 0.38539961],\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_gamma = np.array(\n",
    "    [\n",
    "        [9.99091160e-01, 2.30837264e-04, 6.78002891e-04],\n",
    "        [2.57471392e-03, 6.61674965e-04, 9.96763611e-01],\n",
    "        [1.05391029e-01, 1.55538232e-03, 8.93053589e-01],\n",
    "        [9.57083053e-01, 2.46060810e-04, 4.26708857e-02],\n",
    "        [1.98160531e-01, 4.92895724e-02, 7.52549897e-01],\n",
    "        [8.73873007e-01, 8.50663941e-05, 1.26041926e-01],\n",
    "        [2.42977093e-02, 1.55752162e-04, 9.75546539e-01],\n",
    "        [5.39784969e-02, 3.39143094e-03, 9.42630072e-01],\n",
    "        [9.87115629e-01, 3.42499417e-03, 9.45937634e-03],\n",
    "        [1.27662403e-01, 1.47198095e-03, 8.70865616e-01],\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_varphi = np.array([4.32922773, 0.06051275, 5.61025951])\n",
    "test_result = update_mus(test_data, test_gamma, test_varphi)\n",
    "test_expected = np.array(\n",
    "    [[0.4338092, 0.73565842], [0.39206226, 0.1474507], [0.66765644, 0.26912141]]\n",
    ")\n",
    "np.testing.assert_array_almost_equal(test_result, test_expected)\n",
    "\n",
    "new_mus = update_mus(data, gamma, varphi)\n",
    "print(new_mus)\n",
    "\n",
    "\n",
    "update_mus.assert_no_imports()\n",
    "update_mus.assert_not_too_many_loops()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a6326f7f7e5dcc53c4cc029270bd271",
     "grade": true,
     "grade_id": "cell-e0166fb2c5d77435",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from expected import get_exercise_3_4\n",
    "\n",
    "new_mus = get_exercise_3_4()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c9c9b531983fe2cbd2f1039055c6d57",
     "grade": false,
     "grade_id": "cell-ec7b366de91c8f6b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise 3.5: Compute the cluster covariance matrices (10 points).\n",
    "\n",
    "* In this exercise we will compute the cluster covariance matrices $\\Large{\\Sigma \\in \\mathbb{R}^{(K, d, d)}}$.\n",
    "* However, instead of implementing a function that computes the covariance matrices, you are provided a\n",
    "naive implementation that used a nested loop. This is not efficient and should be replaced by a vectorized implementation.\n",
    "\n",
    "* Speed up the given implementation using only one loop instead of two.\n",
    "\n",
    "$$\\Large{\n",
    "\\Sigma_k = \\frac{\\sum_{n=1}^N \\gamma_{nk} (x_n - \\mu_k)(x_n - \\mu_k)^{\\top} }{\\varphi_k}\n",
    "}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "145d2c5d9752121aca100c01a0de87bc",
     "grade": false,
     "grade_id": "cell-18d5a74e6e7a6bd9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def update_sigmas_slow(\n",
    "    X: np.ndarray, mus: np.ndarray, gamma: np.ndarray, varphi: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate the updated cluster covariances.\n",
    "\n",
    "    Args:\n",
    "        X: The datapoints\n",
    "        mus: The cluster means\n",
    "        gamma: The cluster membership/assignment\n",
    "        varphi: The proportionality of the clusters\n",
    "\n",
    "    Returns:\n",
    "        The updated cluster covariances\n",
    "    \"\"\"\n",
    "    K, d = mus.shape\n",
    "    N, _ = X.shape\n",
    "\n",
    "    # K is the number of clusters\n",
    "    # d is the dimensionality of the data\n",
    "    # N is the number of datapoints\n",
    "\n",
    "    sigmas = np.zeros((K, d, d))\n",
    "    for k in range(K):\n",
    "        sigma = sigmas[k]\n",
    "        for n in range(N):\n",
    "            x_mu = X[n] - mus[k]\n",
    "            sigma += gamma[n, k] * np.outer(x_mu, x_mu) / varphi[k]\n",
    "\n",
    "        # Sigmas[k] = Sigma\n",
    "\n",
    "    return sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "165cddc9b2aff321dbdbda27ab86a8ca",
     "grade": false,
     "grade_id": "cell-5c8d029e5ab96fad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "new_sigmas = update_sigmas_slow(data, mus, gamma, varphi)\n",
    "new_sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "86654a3bc4b8665a3b50527131e4af70",
     "grade": false,
     "grade_id": "cell-809583b1b00445d9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@no_imports\n",
    "@max_allowed_loops(1)\n",
    "def update_sigmas(\n",
    "    X: np.ndarray, mus: np.ndarray, gamma: np.ndarray, varphi: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    K, d = mus.shape\n",
    "    # YOUR CODE HERE\n",
    "    K, d = mus.shape\n",
    "    N, _ = X.shape\n",
    "\n",
    "    # K is the number of clusters\n",
    "    # d is the dimensionality of the data\n",
    "    # N is the number of datapoints\n",
    "\n",
    "#     sigmas = np.zeros((K, d, d))\n",
    "#     for k in range(K):\n",
    "#         sigma = sigmas[k]\n",
    "#         x_mu = X - mus[k]\n",
    "#         print(x_mu.shape)\n",
    "#         print( (x_mu @ x_mu.T).shape)\n",
    "#         print(gamma[:, k].shape)\n",
    "#         test = gamma[:,k].reshape((1,gamma[:, k].shape[0])) @ (x_mu @ x_mu.T)\n",
    "#         print(varphi[k].shape)\n",
    "#         sigmas[k] = test / varphi[k]\n",
    "        \n",
    "        \n",
    "    sigmas = np.zeros((K, d, d))\n",
    "    x_mu = X - mus\n",
    "    test = gamma[n] @ (x_mu @ x_mu.T) / varphi\n",
    "    print(test.shape)\n",
    "    test = test.reshape(test.shape[0], 1, 1)\n",
    "    sigma\n",
    "\n",
    "        # Sigmas[k] = Sigma\n",
    "\n",
    "        # Sigmas[k] = Sigma\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "\n",
    "    return sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae0b9fd35de96c6ca10acc7404121c54",
     "grade": true,
     "grade_id": "cell-f871a093f5044605",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# we don't care about the actual result we just want the result to be the same as the\n",
    "# slow version. We assume that the slow version is correct.\n",
    "rng = np.random.RandomState(0)\n",
    "for _ in range(100):\n",
    "    n_datapoints = rng.randint(20, 1000)\n",
    "    n_dimensions = rng.randint(2, 6)\n",
    "    n_clusters = rng.randint(2, 5)\n",
    "\n",
    "    test_data = rng.rand(n_datapoints, n_dimensions)\n",
    "    test_mus = rng.rand(n_clusters, n_dimensions)\n",
    "    test_gamma = rng.rand(n_datapoints, n_clusters)\n",
    "    test_varphi = rng.rand(n_clusters)\n",
    "\n",
    "    slow_sigmas = update_sigmas_slow(test_data, test_mus, test_gamma, test_varphi)\n",
    "    fast_sigmas = update_sigmas(test_data, test_mus, test_gamma, test_varphi)\n",
    "\n",
    "    np.testing.assert_array_almost_equal(slow_sigmas, fast_sigmas)\n",
    "\n",
    "\n",
    "new_sigmas = update_sigmas(data, mus, gamma, varphi)\n",
    "np.testing.assert_array_equal(new_sigmas.shape, (3, 2, 2))\n",
    "np.testing.assert_array_less(new_sigmas, 5.2)\n",
    "np.testing.assert_array_less(-0.7, new_sigmas)\n",
    "\n",
    "update_sigmas.assert_no_imports()\n",
    "update_sigmas.assert_not_too_many_loops()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0eb9c30bc0c37cd53152abd5c76e85a",
     "grade": true,
     "grade_id": "cell-059d03480366272c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from expected import get_exercise_3_5\n",
    "\n",
    "new_sigmas = get_exercise_3_5()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aaa891ed941c025adda1bea58a25ad6d",
     "grade": false,
     "grade_id": "cell-5838e9607718c97b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise 3.6: Applying the algorithm (5 points).\n",
    "\n",
    "The final part is to put all everything we have implemented together. In order to achieve this you will have to implement the for-loop that iterates over the steps of the algorithm. You only have to implement the algorithm steps. The rest of the code is provided. Make sure to store the gamma matrix in the variable `gamma`. The function is marked with one allowed loop, however that loop is used for the algorithm iterations. The part that you have to implement cannot use any loops.\n",
    "\n",
    "When we test your code, all the above functions will be overwritten with correct implementations, so even if you have not been able to implement all the steps of the algorithm, you should still attempt to implement the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4144bd524c597a2a4c7b99eed4119277",
     "grade": false,
     "grade_id": "cell-166f08ba7bf4af68",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@no_imports\n",
    "@max_allowed_loops(1)\n",
    "def apply_algorithm(\n",
    "    data,\n",
    "    initial_pi: np.ndarray,\n",
    "    initial_mus: np.ndarray,\n",
    "    initialize_sigmas: np.ndarray,\n",
    "    n_iterations: int = 60,\n",
    "    do_plot: bool = False,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply the algorithm on the data. The steps are the following:\n",
    "\n",
    "    1. Calculate the gamma matrix (gamma_hat, gamma)\n",
    "    2. Calculate the soft number of cluster points (varphi)\n",
    "    3. Update the proportions of the clusters (pi)\n",
    "    4. Calculate the cluster means (mus)\n",
    "    5. Calculate the cluster covariances (sigmas)\n",
    "    6. Repeat steps 1-5 for `n_iterations`\n",
    "\n",
    "    Args:\n",
    "        data: The data to cluster\n",
    "        initial_pi: The initial cluster proportions\n",
    "        initial_mus: The initial cluster means\n",
    "        initialize_sigmas: The initial cluster covariances\n",
    "        n_iterations: The number of iterations to run\n",
    "\n",
    "    Returns:\n",
    "        The final gamma matrix\n",
    "    \"\"\"\n",
    "    mus = initial_mus\n",
    "    sigmas = initialize_sigmas\n",
    "    pi = initial_pi\n",
    "\n",
    "    gammas = []\n",
    "    for i in range(n_iterations):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError(\"Relplace this line with your code\")\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "\n",
    "        gammas.append(gamma)\n",
    "\n",
    "        if do_plot and (i % 10 == 0 or i == n_iterations - 1):\n",
    "            labels = np.argmax(gamma, axis=1)\n",
    "            plot_clusters(data, labels, f\"Estimated distribution | Step {i}\")\n",
    "            plt.show()\n",
    "\n",
    "    return np.array(gammas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e01fc55c00f3575c3c2f00cb95773b36",
     "grade": true,
     "grade_id": "cell-8ee7df3fcb979c70",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "output = output = apply_algorithm(data, pi, mus, sigmas)\n",
    "np.testing.assert_array_equal(output.shape, (60, 998, 3))\n",
    "np.testing.assert_array_less(output, 1.0 + 1e-6)\n",
    "np.testing.assert_array_less(0.0 - 1e-6, output)\n",
    "\n",
    "apply_algorithm.assert_no_imports()\n",
    "apply_algorithm.assert_not_too_many_loops()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb4e05b71e55d907af53d75180f00024",
     "grade": false,
     "grade_id": "cell-02366fe90e6cbd61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "apply_algorithm(data, pi, mus, sigmas, do_plot=True);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
